{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the EDA process I didn't hit many roadblocks besides figuring out the most efficient way to fill NaN values if they could not be dropped. This problem appeared while dealing with the attributes of the businesses. With 36 attributes it's hard to determine which ones were most important but eventually I chose the ones that the top ranked restaurants have that lower ranked restaurants did not have. Other setbacks I encountered were finding correlations in the Nevada businesses because the businesses are so densely packed in a small span of area. It seemed to rule out and geographical affect on rankings unless there was a tourist attraction nearby.\n",
    "\n",
    "The most setbacks came from the Natural Language processing parts of the project. First the dataset is very large and if the kernel crashes then it would take a few minutes to reload the data. Next there were a lot of stopwords to sort through. Something I did discover through natural language processing is that the reviews were made up of more rich text than the tips. After tokenizing and vectorizing the tips text I was disappointed by how meaningless the words were. \n",
    "\n",
    "Finally I ran textblob on the reviews with a small, poorly-trained train set and the results were very poor. I hope to find a set of positive and negative words to use for my training because coming up with them on my own was tough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
